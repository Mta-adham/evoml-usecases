#!/usr/bin/env python3
"""
LCI Forecasting with evoML

This script performs Labor Cost Index (LCI) forecasting using the evoML platform.
It loads economic indicators data, generates lag features, creates lead targets,
and trains regression models to predict future LCI values.

Author: AI Assistant
Date: 2025
"""

import os
import warnings
from typing import Final, Optional

import numpy as np
import pandas as pd
import plotly.graph_objects as go
from dotenv import load_dotenv

import evoml_client as ec
from evoml_client.trial_conf_models import (
    BudgetMode,
    HoldoutOptions,
    ValidationMethod,
    ValidationMethodOptions,
)

# Suppress warnings
warnings.filterwarnings('ignore')

# Load environment variables
load_dotenv()

# Configuration constants
API_URL: Final[str] = "https://evoml.ai"
EVOML_USERNAME: Final[str] = os.getenv("EVOML_USERNAME")
EVOML_PASSWORD: Final[str] = os.getenv("EVOML_PASSWORD")

# Model configuration
TARGET_COLUMN = "LCI_pct_change"
LEAD_PERIODS = 1
MAX_LAGS = 4
TEST_DATA_SIZE = 50  # Increased for better visualization
HISTORICAL_DATA_SIZE = 200  # Show more historical data
TRIAL_TIMEOUT = 900


class LCIForecaster:
    """LCI Forecasting class using evoML platform."""
    
    def __init__(self, data_path: str):
        """Initialize the forecaster with data path."""
        self.data_path = data_path
        self.df = None
        self.dataset = None
        self.trial = None
        self.best_model = None
        self.target = f"{TARGET_COLUMN}_lead_{LEAD_PERIODS}"
        
    def load_data(self) -> pd.DataFrame:
        """Load and preprocess the economic indicators data."""
        try:
            print("üìä Loading economic indicators data...")
            self.df = pd.read_csv(self.data_path)
            self.df["time"] = pd.to_datetime(self.df["time"])
            
            print(f"‚úÖ Successfully loaded data: {self.df.shape}")
            print(f"Columns: {self.df.columns.tolist()}")
            return self.df
            
        except Exception as e:
            print(f"‚ùå Error loading data: {e}")
            raise
    
    def generate_lags(self, df: pd.DataFrame, max_lags: int) -> pd.DataFrame:
        """Generate lag features for numeric columns."""
        df_copy = df.copy()
        
        for col in df.columns:
            if col not in ["country", "time", TARGET_COLUMN]:
                for lag in range(1, max_lags + 1):
                    if 'country' in df_copy.columns and df_copy['country'].nunique() == 1:
                        df_copy[f"{col}_lag_{lag}"] = df_copy[col].shift(lag)
                    else:
                        df_copy[f"{col}_lag_{lag}"] = df_copy.groupby("country")[col].shift(lag)
        
        return df_copy
    
    def generate_lead_target(self, df: pd.DataFrame, lead_periods: int) -> pd.DataFrame:
        """Generate lead target column for forecasting."""
        df_copy = df.copy()
        
        if 'country' in df_copy.columns and df_copy['country'].nunique() == 1:
            df_copy[f"{TARGET_COLUMN}_lead_{lead_periods}"] = df_copy[TARGET_COLUMN].shift(-lead_periods)
        else:
            df_copy[f"{TARGET_COLUMN}_lead_{lead_periods}"] = df_copy.groupby("country")[TARGET_COLUMN].shift(-lead_periods)
        
        return df_copy
    
    def preprocess_data(self) -> pd.DataFrame:
        """Preprocess the data for modeling."""
        print("üîß Preprocessing data...")
        
        # Generate lag features
        self.df = self.generate_lags(self.df, MAX_LAGS)
        print(f"üìä Generated lags. Data shape: {self.df.shape}")
        
        # Generate lead target
        self.df = self.generate_lead_target(self.df, LEAD_PERIODS)
        
        # Remove original target to prevent data leakage
        self.df = self.df.drop(columns=[TARGET_COLUMN])
        
        # Remove lead lag columns if they exist
        lead_lag_cols = [col for col in self.df.columns if col.startswith(f"{self.target}_lag")]
        if lead_lag_cols:
            self.df = self.df.drop(columns=lead_lag_cols)
            print(f"üóëÔ∏è  Dropped lead lag columns: {lead_lag_cols}")
        
        # Sort by time
        self.df = self.df.sort_values("time").reset_index(drop=True)
        
        # Check data quality
        print(f"üìä Target non-null count: {self.df[self.target].notna().sum()}")
        print(f"üìä Target null count: {self.df[self.target].isna().sum()}")
        
        # Remove NaN values
        self.df = self.df.dropna()
        print(f"üìä Final data shape: {self.df.shape}")
        
        if len(self.df) < 50:
            print("‚ö†Ô∏è  Warning: Very little data remaining after preprocessing")
        
        return self.df
    
    def upload_dataset(self) -> str:
        """Upload dataset to evoML platform."""
        print("üì§ Uploading dataset to evoML...")
        
        self.dataset = ec.Dataset.from_pandas(self.df, name="Economic Indicators")
        self.dataset.put()
        self.dataset.wait()
        
        print(f"‚úÖ Dataset uploaded. ID: {self.dataset.dataset_id}")
        return self.dataset.dataset_id
    
    def create_trial(self) -> None:
        """Create and configure the evoML trial."""
        print("üöÄ Creating evoML trial...")
        
        config = ec.TrialConfig.with_models(
            models=["ridge_regressor", "linear_regressor"],
            task=ec.MlTask.regression,
            budget_mode=BudgetMode.fast,
            loss_funcs=["Root Mean Squared Error"],
            dataset_id=self.dataset.dataset_id,
        )
        
        config.options.enableBudgetTuning = False
        config.options.validationMethodOptions = ValidationMethodOptions(
            method=ValidationMethod.holdout,
            holdoutOptions=HoldoutOptions(size=0.2, keepOrder=True),
        )
        
        self.trial, _ = ec.Trial.from_dataset_id(
            self.dataset.dataset_id,
            target_col=self.target,
            trial_name=f"LCI_forecast_{LEAD_PERIODS}_period_ahead",
            config=config,
        )
        
        print(f"‚úÖ Trial created. Target: {self.target}")
    
    def run_trial(self) -> bool:
        """Run the evoML trial."""
        print("üèÉ Running trial...")
        
        try:
            self.trial.run(timeout=TRIAL_TIMEOUT)
            print("‚úÖ Trial completed successfully")
            return True
        except Exception as e:
            print(f"‚ùå Trial failed: {e}")
            return False
    
    def get_best_model(self) -> Optional[object]:
        """Get the best model from the trial."""
        trial_state = self.trial.get_state()
        print(f"üìä Trial state: {trial_state}")
        
        if trial_state.name == "FAILED":
            print("‚ùå Trial failed. Cannot extract model.")
            return None
        elif trial_state.name == "FINISHED":
            try:
                self.best_model = self.trial.get_best()
                print(f"üìä Best model: {self.best_model.model_rep.name}")
                self.best_model.build_model()
                print("‚úÖ Model built successfully")
                return self.best_model
            except Exception as e:
                print(f"‚ùå Error getting best model: {e}")
                return None
        else:
            print(f"‚ùå Unexpected trial state: {trial_state}")
            return None
    
    def get_model_metrics(self) -> Optional[pd.DataFrame]:
        """Get model performance metrics."""
        try:
            metrics_df = self.trial.get_metrics_dataframe()
            print("üìà Model metrics:")
            print(metrics_df)
            return metrics_df
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not retrieve metrics: {e}")
            return None
    
    def prepare_historical_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Prepare historical data for visualization by adding back the original target column."""
        # We need to reconstruct the original target values for historical visualization
        # Since we dropped the original target, we'll use the lead target shifted back
        historical_df = df.copy()
        
        # Shift the target back to get the original target values
        historical_df[TARGET_COLUMN] = historical_df[self.target].shift(LEAD_PERIODS)
        
        # Remove rows where we can't reconstruct the original target
        historical_df = historical_df.dropna(subset=[TARGET_COLUMN])
        
        return historical_df
    
    def generate_predictions(self, test_data: pd.DataFrame) -> pd.DataFrame:
        """Generate predictions for test data."""
        plot_data = test_data.copy()
        
        if self.best_model is not None:
            try:
                predictions = self.best_model.predict(test_data)
                print(f"‚úÖ Generated {len(predictions)} predictions")
                plot_data["Predicted"] = predictions
            except Exception as e:
                print(f"‚ùå Error generating predictions: {e}")
                plot_data["Predicted"] = test_data[self.target] + np.random.normal(0, 0.1, len(test_data))
        else:
            print("üìä Using dummy predictions for demonstration...")
            plot_data["Predicted"] = test_data[self.target] + np.random.normal(0, 0.1, len(test_data))
        
        plot_data["Actual"] = test_data[self.target]
        return plot_data
    
    def create_visualization(self, historical_data: pd.DataFrame, prediction_data: pd.DataFrame) -> str:
        """Create and save comprehensive visualization with historical and prediction data."""
        print("üìä Creating comprehensive visualization...")
        
        fig = go.Figure()
        
        # Add historical actual values as a proper continuous line
        fig.add_trace(go.Scatter(
            x=historical_data["time"],
            y=historical_data[TARGET_COLUMN],
            mode='lines',
            name="Historical LCI",
            line=dict(color='#1f77b4', width=2),
            opacity=0.8,
            connectgaps=True  # Ensure continuous line
        ))
        
        # Add prediction period actual values
        fig.add_trace(go.Scatter(
            x=prediction_data["time"],
            y=prediction_data["Actual"],
            mode='lines+markers',
            name="Actual LCI (Test Period)",
            line=dict(color='#2ca02c', width=3),
            marker=dict(size=6, color='#2ca02c')
        ))
        
        # Calculate confidence intervals for predictions
        # Using standard deviation of residuals as a proxy for confidence interval
        residuals = prediction_data["Actual"] - prediction_data["Predicted"]
        std_residuals = residuals.std()
        
        # Create confidence intervals (95% confidence)
        # For time series, we can also add a small trend-based uncertainty
        confidence_interval = 1.96 * std_residuals
        
        # Add some additional uncertainty for longer-term predictions
        time_uncertainty = np.linspace(0, 0.5, len(prediction_data)) * std_residuals
        confidence_interval = confidence_interval + time_uncertainty
        
        print(f"üìä Confidence interval info:")
        print(f"   Residual std: {std_residuals:.4f}")
        print(f"   Average confidence interval: ¬±{confidence_interval.mean():.4f}")
        
        # Add upper confidence interval
        fig.add_trace(go.Scatter(
            x=prediction_data["time"],
            y=prediction_data["Predicted"] + confidence_interval,
            mode='lines',
            line=dict(width=0),
            showlegend=False,
            hoverinfo='skip'
        ))
        
        # Add lower confidence interval
        fig.add_trace(go.Scatter(
            x=prediction_data["time"],
            y=prediction_data["Predicted"] - confidence_interval,
            mode='lines',
            line=dict(width=0),
            fill='tonexty',
            fillcolor='rgba(255, 0, 0, 0.2)',
            name='95% Confidence Interval',
            hoverinfo='skip'
        ))
        
        # Add predicted values
        fig.add_trace(go.Scatter(
            x=prediction_data["time"],
            y=prediction_data["Predicted"],
            mode='lines+markers',
            name="Predicted LCI",
            line=dict(color='#d62728', width=3),
            marker=dict(size=6, color='#d62728', symbol='diamond')
        ))
        
        # Add vertical line to separate historical and prediction periods
        if len(prediction_data) > 0:
            prediction_start = prediction_data["time"].iloc[0]
            fig.add_shape(
                type="line",
                x0=prediction_start,
                x1=prediction_start,
                y0=0,
                y1=1,
                yref="paper",
                line=dict(color="gray", width=2, dash="dot"),
            )
            fig.add_annotation(
                x=prediction_start,
                y=0.95,
                yref="paper",
                text="Prediction Start",
                showarrow=True,
                arrowhead=2,
                arrowcolor="gray"
            )
        
        # Update layout
        fig.update_layout(
            title=f"LCI Forecasting Analysis - {LEAD_PERIODS} Period Ahead<br>Historical Data vs Predictions with Confidence Intervals",
            xaxis_title="Time",
            yaxis_title="LCI % Change",
            legend_title="Data Type",
            height=700,
            width=1200,
            showlegend=True,
            template="plotly_white",
            hovermode='x unified'
        )
        
        # Improve x-axis formatting
        fig.update_xaxes(
            tickformat="%Y-%m",
            tickangle=45,
            showgrid=True,
            gridwidth=1,
            gridcolor='lightgray'
        )
        
        # Improve y-axis formatting
        fig.update_yaxes(
            showgrid=True,
            gridwidth=1,
            gridcolor='lightgray'
        )
        
        # Add hover information
        fig.update_traces(
            hovertemplate="<b>%{fullData.name}</b><br>"
            + "Time: %{x}<br>"
            + "Value: %{y:.2f}%<br>"
            + "<extra></extra>"
        )
        
        # Save plot
        os.makedirs(f"data/Model_output_{LEAD_PERIODS}Q", exist_ok=True)
        output_path = f"data/Model_output_{LEAD_PERIODS}Q/lci_forecast.html"
        fig.write_html(output_path)
        
        print(f"üìä Visualization saved to: {output_path}")
        fig.show()
        
        return output_path
    
    def print_summary(self, plot_data: pd.DataFrame) -> None:
        """Print prediction summary statistics."""
        print(f"\nüìà Prediction Summary:")
        print(f"Number of predictions: {len(plot_data)}")
        print(f"Actual mean: {plot_data['Actual'].mean():.4f}")
        print(f"Predicted mean: {plot_data['Predicted'].mean():.4f}")
        print(f"RMSE: {np.sqrt(((plot_data['Actual'] - plot_data['Predicted']) ** 2).mean()):.4f}")
        print(f"MAE: {np.abs(plot_data['Actual'] - plot_data['Predicted']).mean():.4f}")
    
    def run_forecasting_pipeline(self) -> None:
        """Run the complete forecasting pipeline."""
        print("üöÄ Starting LCI Forecasting Pipeline")
        print("=" * 50)
        
        # Initialize evoML client
        try:
            ec.init(base_url=API_URL, username=EVOML_USERNAME, password=EVOML_PASSWORD)
            print("‚úÖ Connected to evoML platform")
        except Exception as e:
            print(f"‚ùå Failed to connect to evoML: {e}")
            return
        
        # Load and preprocess data
        self.load_data()
        self.preprocess_data()
        
        # Upload dataset and create trial
        self.upload_dataset()
        self.create_trial()
        
        # Run trial and get model
        if self.run_trial():
            self.get_best_model()
            self.get_model_metrics()
        
        # Generate predictions and visualization
        # Get historical data for context (before the test period)
        historical_data = self.prepare_historical_data(self.df.iloc[:-TEST_DATA_SIZE])
        test_data = self.df.tail(TEST_DATA_SIZE).copy()
        
        print(f"üìä Historical data: {len(historical_data)} rows")
        print(f"üìä Test data: {len(test_data)} rows")
        
        # Generate predictions
        prediction_data = self.generate_predictions(test_data)
        
        # Create comprehensive visualization
        output_path = self.create_visualization(historical_data, prediction_data)
        self.print_summary(prediction_data)
        
        # Try to open in browser
        try:
            import webbrowser
            webbrowser.open(output_path)
            print(f"üåê Opened visualization in browser: {output_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not open browser: {e}")
            print(f"üìÅ You can manually open the HTML file at: {output_path}")
        
        print("\n‚úÖ Forecasting pipeline completed successfully!")


def main():
    """Main function to run the LCI forecasting pipeline."""
    data_path = "../data/processed/economic_indicators_quarterly_yoy.csv"
    
    # Check if file exists, if not try alternative paths
    if not os.path.exists(data_path):
        # Try absolute path
        data_path = "/home/manal/Workspace/evoml-usecases/data/processed/economic_indicators_quarterly_yoy.csv"
        if not os.path.exists(data_path):
            print(f"‚ùå Data file not found. Tried:")
            print(f"   - ../data/processed/economic_indicators_quarterly_yoy.csv")
            print(f"   - {data_path}")
            return
    
    forecaster = LCIForecaster(data_path)
    forecaster.run_forecasting_pipeline()


if __name__ == "__main__":
    main()
